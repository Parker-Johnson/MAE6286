{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helper import l2_norm, poisson_2d_jacobi, poisson_solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "nx = 101\n",
    "ny = 101\n",
    "xmin, xmax = 0.0, 1.0\n",
    "ymin, ymax = -0.5, 0.5\n",
    "Lx = xmax - xmin\n",
    "Ly = ymax - ymin\n",
    "dx = Lx / (nx -1)\n",
    "dy = Ly / (ny -1)\n",
    "\n",
    "#create grid\n",
    "x = np.linspace(xmin, xmax, num=nx)\n",
    "y = np.linspace(ymin, ymax, num=ny)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# create rhs\n",
    "b = (-2.0 * (np.pi / Lx) * (np.pi / Ly)\n",
    "    * np.sin(np.pi * X / Lx)\n",
    "    * np.cos(np.pi * Y / Ly))\n",
    "\n",
    "# set initial conditions\n",
    "p0 = np.zeros((ny, nx))\n",
    "\n",
    "# compute analytical solution\n",
    "p_exact = poisson_solution(x, y, Lx, Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_2d_steepest_descent(p0, b, dx, dy,\n",
    "                               maxiter=20000, rtol=1e-6):\n",
    "    def A(p):\n",
    "        # apply laplacian operator to p\n",
    "        return (-4.0 * p[1:-1, 1:-1] +\n",
    "               p[1:-1, :-2] + p[1:-1, 2:] +\n",
    "               p[:-2, 1:-1] + p[2:, 1:-1]) / dx**2\n",
    "    p = p0.copy()\n",
    "    r = np.zeros_like(p)\n",
    "    Ar = np.zeros_like(p)\n",
    "    conv = []\n",
    "    diff = rtol + 1\n",
    "    ite = 0\n",
    "    while diff > rtol and ite < maxiter:\n",
    "        pk = p.copy()\n",
    "        \n",
    "        #compute residual\n",
    "        r[1:-1, 1:-1] = b[1:-1, 1:-1] -A(p)\n",
    "        \n",
    "        #compute the laplacian of residual\n",
    "        Ar[1:-1, 1:-1] = A(r)\n",
    "        \n",
    "        #compute step size\n",
    "        alpha = np.sum(r*r) / np.sum(r*Ar)\n",
    "        \n",
    "        #update solution\n",
    "        p = pk + alpha*r\n",
    "        \n",
    "        # dirichlet boundary conditions are automatically enforced.\n",
    "        # compute the relative L2-norm of the difference.\n",
    "        diff = l2_norm(p, pk)\n",
    "        conv.append(diff)\n",
    "        ite += 1\n",
    "    return p, ite, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method of steepest descent: 2 iterations to reach a relative difference of 1.3307695446303778e-16\n"
     ]
    }
   ],
   "source": [
    "# compute the solution using the\n",
    "# method of steepest descent.\n",
    "\n",
    "p, ites, conv_sd = poisson_2d_steepest_descent(p0, b, \n",
    "                                              dx, dy,\n",
    "                                              maxiter=20000,\n",
    "                                              rtol=1e-10)\n",
    "print('Method of steepest descent: {} iterations '.format(ites) +\n",
    "     'to reach a relative difference of {}'.format(conv_sd[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.225076220929745e-05"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the relative L2_Norm of the error.\n",
    "l2_norm(p, p_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will use the method of conjugate gradients\n",
    "\n",
    "def poisson_2d_conjugate_gradient(p0, b,\n",
    "                                  dx, dy, \n",
    "                                  maxiter=20000,\n",
    "                                  rtol= 1e-6):\n",
    "    \n",
    "    def A(p):\n",
    "        #apply the laplacian operator to p.\n",
    "        return (-4.0 * p[1:-1, 1:-1] +\n",
    "               p[1:-1, :-2] + p[1:-1, 2:] \n",
    "               + p[:-2, 1:-1] + p[2:, 1:-1]) / dx**2\n",
    "    p = p0.copy()\n",
    "    r = np.zeros_like(p) # initial residual\n",
    "    Ad = np.zeros_like(p) # to store the mat-vec multiplication\n",
    "    conv = []\n",
    "    diff = rtol + 1\n",
    "    ite = 0\n",
    "    # compute initial residual\n",
    "    r[1:-1, 1:-1] = b[1:-1, 1:-1] - A(p)\n",
    "    # set the initial search directionto be residual\n",
    "    d = r.copy()\n",
    "    while diff > rtol and ite < maxiter:\n",
    "        pk = p.copy()\n",
    "        rk = r.copy()\n",
    "        #compute the laplacian of search direction\n",
    "        Ad[1:-1, 1:-1] = A(d)\n",
    "        \n",
    "        #compute the step size.\n",
    "        alpha = np.sum(r*r) / np.sum(d*Ad)\n",
    "        \n",
    "        #update the solution\n",
    "        p = pk + alpha*d\n",
    "        \n",
    "        #update the residual\n",
    "        r = rk - alpha*Ad\n",
    "        \n",
    "        #update search direction\n",
    "        beta = np.sum(r*r) / np.sum(rk * rk)\n",
    "        d = r + beta*d\n",
    "        \n",
    "        #dirichlet boundary conditions are automatically enforced\n",
    "        # compute the relative L2-norm of difference\n",
    "        diff = l2_norm(p, pk)\n",
    "        conv.append(diff)\n",
    "        ite += 1\n",
    "    return p, ite, conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method of conjugate gradients: 2 iterations to reach a relative difference of 1.2982770796281907e-16\n"
     ]
    }
   ],
   "source": [
    "# compute the solution using conjugate gradients.\n",
    "p, ites, conv_cg = poisson_2d_conjugate_gradient(p0, b,\n",
    "                                                dx, dy,\n",
    "                                                maxiter=20000,\n",
    "                                                rtol=1e-10)\n",
    "print('method of conjugate gradients: {} iterations '.format(ites) +\n",
    "     'to reach a relative difference of {}'.format(conv_cg[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.225076220929585e-05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute relative L2-norm of error\n",
    "l2_norm(p, p_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobi relaxation: 31227 iterations to reach a relative difference of 9.997923503623598e-11\n"
     ]
    }
   ],
   "source": [
    "# compute solution using jacobi relaxation\n",
    "# to compare amount of iterations to solution\n",
    "\n",
    "p, ites, conv_jacobi = poisson_2d_jacobi(p0, b,\n",
    "                                        dx, dy,\n",
    "                                        maxiter=40000,\n",
    "                                        rtol=1e-10)\n",
    "print('Jacobi relaxation: {} iterations '.format(ites) +\n",
    "     'to reach a relative difference of {}'.format(conv_jacobi[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can look at more difficult poisson\n",
    "# problems because conjugate gradient really\n",
    "# helps with these\n",
    "\n",
    "# modify rhs of poisson system.\n",
    "\n",
    "b = (np.sin(np.pi * X/ Lx) *\n",
    "    np.cos(np.pi * Y/ Ly) +\n",
    "    np.sin(6.0 * np.pi * X/ Lx) *\n",
    "    np.sin(6.0 * np.pi * Y/ Ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobi relaxation: 31226 iterations\n",
      "method of steepest descent: 27059 iterations\n",
      "method of conjugate gradients: 3 iterations\n"
     ]
    }
   ],
   "source": [
    "maxiter, rtol = 40000, 1e-10\n",
    "p, ites, conv = poisson_2d_jacobi(p0, b, dx,\n",
    "                                 dy, maxiter=maxiter,\n",
    "                                 rtol=rtol)\n",
    "print('Jacobi relaxation: {} iterations'.format(ites))\n",
    "p, ites, conv = poisson_2d_steepest_descent(p0, b ,dx,\n",
    "                                           dy, maxiter=maxiter,\n",
    "                                           rtol=rtol)\n",
    "print('method of steepest descent: {} iterations'.format(ites))\n",
    "p, ites, conv = poisson_2d_conjugate_gradient(p0, b, dx,\n",
    "                                             dy, maxiter=maxiter,\n",
    "                                             rtol=rtol)\n",
    "print('method of conjugate gradients: {} iterations'.format(ites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
